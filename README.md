# ğŸ“ Student Performance Predictor - End-to-End MLOps Pipeline

[![CI](https://github.com/Ishtiaque-h/student-performance-indicator/actions/workflows/ci.yml/badge.svg)](https://github.com/Ishtiaque-h/student-performance-indicator/actions/workflows/ci.yml)
[![Deploy Staging](https://github.com/Ishtiaque-h/student-performance-indicator/actions/workflows/deploy.yml/badge.svg)](https://github.com/Ishtiaque-h/student-performance-indicator/actions/workflows/deploy.yml)
[![Deploy Production](https://github.com/Ishtiaque-h/student-performance-indicator/actions/workflows/cd-cloudrun.yml/badge.svg)](https://github.com/Ishtiaque-h/student-performance-indicator/actions/workflows/cd-cloudrun.yml)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)

A **production-grade machine learning system** that predicts student math scores based on demographic and educational factors. This project demonstrates end-to-end MLOps practices including automated retraining, quality gates, staged deployments, and cloud-native architecture.

ğŸ”— **Live Demo**: [https://student-performance-api-[YOUR-DOMAIN].run.app](https://student-performance-api-654581958038.us-central1.run.app)

---

## ğŸ¯ Project Highlights

Focus isn't just a model - it's a **complete ML production system**:

- âœ… **10+ ML models** with hyperparameter tuning (RandomizedSearch â†’ GridSearch)
- âœ… **Automated CI/CD** with GitHub Actions
- âœ… **Staging + Production environments** with manual promotion gates
- âœ… **Weekly automated retraining** with quality thresholds
- âœ… **FastAPI REST service** with health checks and schema introspection
- âœ… **Cloud-native deployment** on Google Cloud Run
- âœ… **MLflow integration** for experiment tracking
- âœ… **Docker containerization** with multi-stage builds
- âœ… **Comprehensive testing** (smoke tests, dynamic schema validation, post-deploy validation)

---

## ğŸ“Š Problem Statement

**Question**: How do demographic and educational factors affect student academic performance?

**Dataset**: [Kaggle Student Performance Dataset](https://www.kaggle.com/datasets/spscientist/students-performance-in-exams)
- 1,000 students
- 8 features: gender, race/ethnicity, parental education, lunch type, test prep course, scores
- **Target**: Math score (regression task)
- **Features used**: 5 categorical features (excluded reading/writing scores to prevent data leakage)

---

## ğŸ—ï¸ Architecture

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Developer Workflow                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               GitHub Actions (CI/CD)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ CI: Lint, Format, Smoke Tests                            â”‚
â”‚  â€¢ Staging: Auto-deploy on push to main                     â”‚
â”‚  â€¢ Production: Tag-based deployment (manual)                â”‚
â”‚  â€¢ Retrain: Weekly scheduled (Monday 7 AM UTC)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Google Cloud Storage (GCS)       â”‚   Artifact Registry  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Model artifacts (model.pkl)        â”‚ â€¢ Docker images      â”‚
â”‚ â€¢ Preprocessor (preprocessor.pkl)    â”‚ â€¢ Tagged versions    â”‚
â”‚ â€¢ MLflow experiments                 â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Google Cloud Run (Serverless)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Staging: student-performance-api-staging                   â”‚
â”‚  Production: student-performance-api                        â”‚
â”‚  â€¢ Auto-scaling (0â†’N instances)                             â”‚
â”‚  â€¢ HTTPS endpoints                                          â”‚
â”‚  â€¢ Health monitoring                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ MLOps Pipeline

### **Deployment Flow**

```
Developer Push â†’ main branch
    â†“
CI: Lint + Format + Smoke Tests (GitHub Actions)
    â†“
Train Model (10 models + hyperparameter tuning)
    â†“
Build Docker Image (with artifacts)
    â†“
Deploy to STAGING (auto)
    â†“
[Manual Testing & Review]
    â†“
Create Release Tag (e.g., v3.2.6)
    â†“
Deploy to PRODUCTION (auto-triggered by tag)
    â†“
Post-Deploy Smoke Tests (health + predictions)
```

### **Automated Retraining Flow**

```
Schedule: Every Monday 7 AM UTC
    â†“
Retrain all models with latest data
    â†“
Quality Gate: test_r2 >= 0.10
    â”œâ”€ PASS â†’ Deploy to Staging
    â””â”€ FAIL â†’ Stop (notification sent)
    â†“
Manual Review: Check MLflow metrics
    â†“
Manual Promotion: Create release tag if satisfied
    â†“
Production Deployment
```

---

## ğŸ§  Machine Learning

### **Models Evaluated**

| Model | Description | Hyperparams Tuned |
|-------|-------------|-------------------|
| **Linear Regression** | Baseline | - |
| **Ridge** | L2 regularization | `alpha` |
| **Lasso** | L1 regularization | `alpha` |
| **KNN** | K-nearest neighbors | `n_neighbors`, `weights`, `p` |
| **Decision Tree** | Single tree | `max_depth`, `criterion` |
| **Random Forest** | Ensemble of trees | `n_estimators`, `max_depth`, `max_features` |
| **AdaBoost** | Boosting ensemble | `n_estimators`, `learning_rate` |
| **Gradient Boosting** | GB ensemble | `n_estimators`, `learning_rate`, `max_depth` |
| **XGBoost** | Advanced GB | `n_estimators`, `learning_rate`, `max_depth`, `subsample` |
| **CatBoost** | Cat-optimized GB | `iterations`, `learning_rate`, `depth` |

### **Hyperparameter Tuning Strategy**

**Two-stage approach**:

1. **Broad Search** (RandomizedSearchCV):
   - 20 iterations per model
   - Wide parameter ranges
   - Identifies promising regions

2. **Refined Search** (GridSearch):
   - Narrows around best params from stage 1
   - Custom refinement strategies:
     - `float_log`: Multiplicative factors (e.g., 0.5x, 1x, 2x)
     - `int_window`: Additive deltas (e.g., -50, 0, +50)
     - `categorical`: Discrete choices

### **Model Selection**

- **Scoring metric**: Negative MSE (5-fold CV)
- **Selection criterion**: Prefers CV score over test RÂ² (prevents overfitting)
- **Quality gate**: Test RÂ² â‰¥ 0.10 required for production promotion

### **Preprocessing**

```python
Numerical Features: 2 (Here we used none to prevent data leakage)
  â”œâ”€ Imputation: SimpleImputer(strategy='median')
  â””â”€ Standardization: StandardScaler()

Categorical Features: 5
  â”œâ”€ Imputation: SimpleImputer(strategy='most_frequent')
  â””â”€ Encoding: OneHotEncoder(handle_unknown='ignore')
```

**Output**: Sparse matrix (memory-efficient) with automatic densification for models that require it (KNN, Decision Trees, Boosting models).

---

## ğŸš€ Quick Start

### **Prerequisites**

- Python 3.11+
- Docker (optional, for local testing)
- GCP account (for deployment)

### **Installation**

```bash
# Clone the repository
git clone https://github.com/Ishtiaque-h/student-performance-indicator.git
cd student-performance-indicator

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -e ".[dev,api,ml,mlops]"
```

### **Train Model Locally**

```bash
# Train all models with hyperparameter tuning
python scripts/train_and_publish.py \
  --registry-uri gs://YOUR-BUCKET/student-performance \
  --index-latest

# Artifacts saved to: artifacts/
# - model.pkl
# - preprocessor.pkl
# - model_report.json
# - ingestion_meta.json
```

### **Run API Locally**

```bash
# Start FastAPI server
uvicorn student_performance.api:app --reload --port 8000

# Test health endpoint
curl http://localhost:8000/health

# Make prediction
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "gender": "female",
    "race_ethnicity": "group B",
    "parental_level_of_education": "bachelor'\''s degree",
    "lunch": "standard",
    "test_preparation_course": "none"
  }'
```

### **Run Tests**

```bash
# Smoke tests
pytest -m smoke -v

# All tests
pytest -v

# With coverage
pytest --cov=student_performance
```

---

## ğŸ“ Project Structure

```
student-performance-indicator/
â”œâ”€â”€ .github/workflows/          # CI/CD pipelines
â”‚   â”œâ”€â”€ ci.yml                  # Lint, format, tests
â”‚   â”œâ”€â”€ deploy.yml              # Staging deployment
â”‚   â”œâ”€â”€ cd-cloudrun.yml         # Production deployment
â”‚   â””â”€â”€ retrain.yml             # Scheduled retraining
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/stud.csv            # Source dataset
â”œâ”€â”€ src/student_performance/
â”‚   â”œâ”€â”€ components/             # ML pipeline components
â”‚   â”‚   â”œâ”€â”€ config.py           # Centralized configuration
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py  # Data loading + splitting
â”‚   â”‚   â”œâ”€â”€ data_transformation.py  # Preprocessing
â”‚   â”‚   â””â”€â”€ model_trainer.py   # Model training + tuning
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ train_pipeline.py  # Training orchestration
â”‚   â”‚   â””â”€â”€ predict_pipeline.py  # Inference pipeline
â”‚   â”œâ”€â”€ mlops/
â”‚   â”‚   â””â”€â”€ mlflow_logger.py   # MLflow integration
â”‚   â”œâ”€â”€ registry/
â”‚   â”‚   â””â”€â”€ gcs_registry.py    # GCS artifact management
â”‚   â”œâ”€â”€ api.py                  # FastAPI application
â”‚   â”œâ”€â”€ modeling.py             # evaluate_models implementation
â”‚   â””â”€â”€ utils.py                # Utility functions
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ train_and_publish.py   # CLI for training + publishing
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_smoke.py           # Smoke tests
â”œâ”€â”€ Dockerfile                  # Multi-stage Docker build
â”œâ”€â”€ pyproject.toml              # Package configuration
â””â”€â”€ README.md
```

---

## ğŸ”§ Configuration

All configuration is centralized in `src/student_performance/components/config.py`:

```python
CONFIG = PipelineConfig(
    dataset=DatasetConfig(
        data_rel_path="data/raw/stud.csv",
        target_col="math_score",
        drop_cols=["reading_score", "writing_score"]
    ),
    split=SplitConfig(
        test_size=0.2,
        random_state=42
    ),
    tuning=TuningConfig(
        cv=5,
        scoring="r2",
        random_n_iter=25,
        prefer_cv_for_selection=True
    )
)
```

**To use a different dataset**: Update `CONFIG.dataset.data_rel_path`, `target_col`, and `drop_cols`.

---

## ğŸ“Š API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/health` | Health check + artifact status |
| `GET` | `/` | Web UI (form-based prediction) |
| `GET` | `/schema` | Feature schema (from trained preprocessor) |
| `GET` | `/meta` | Artifact metadata (paths, versions) |
| `POST` | `/predict` | Single prediction |
| `POST` | `/predict_batch` | Batch predictions |

### **Example Request**

```bash
curl -X POST https://student-performance-api-[YOUR-DOMAIN].run.app/predict \
  -H "Content-Type: application/json" \
  -d '{
    "gender": "male",
    "race_ethnicity": "group C",
    "parental_level_of_education": "some college",
    "lunch": "free/reduced",
    "test_preparation_course": "completed"
  }'
```

**Response**:
```json
{
  "prediction": 68.4
}
```

---

## ğŸ”’ Production Deployment

### **Infrastructure**

- **Platform**: Google Cloud Run (serverless)
- **Authentication**: Workload Identity Federation (no service account keys!)
- **Artifact Storage**: Google Cloud Storage
- **Container Registry**: Google Artifact Registry
- **Secrets Management**: GitHub Secrets

### **Deployment Process**

1. **Manual Promotion** (current):
   ```bash
   # After reviewing staging deployment
   git tag v3.3.0
   git push origin v3.3.0
   ```

2. **Automated CI/CD**:
   - Tag push triggers `cd-cloudrun.yml`
   - Trains model with tagged code
   - Builds Docker image
   - Deploys to Cloud Run (production)
   - Runs post-deploy smoke tests

3. **Quality Gates**:
   - Pre-deployment: RÂ² â‰¥ 0.10
   - Post-deployment: Health check + prediction validation

---

## ğŸ“ˆ Monitoring & Observability

### **Current**

- âœ… Post-deploy smoke tests (health + prediction validation)
- âœ… MLflow experiment tracking
- âœ… Artifact versioning (GCS + tags)
- âœ… Deployment logs (Cloud Run)

### **Future Enhancements**

- [ ] Data drift detection
- [ ] Model performance monitoring
- [ ] Cloud Monitoring alerts
- [ ] A/B testing framework
- [ ] Gradual rollouts (canary deployments)

---

## ğŸ§ª Testing Strategy

| Test Type | Coverage | When |
|-----------|----------|------|
| **Smoke Tests** | End-to-end pipeline | Every PR + deployment |
| **Linting** | Code quality (ruff) | Every commit |
| **Formatting** | Code style (black) | Every commit |
| **Post-Deploy** | Live API validation | After production deploy |

---

## ğŸ¤ Contributing

This is a portfolio project, but feedback is welcome!

1. Fork the repo
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file.

---

## ğŸ‘¤ Author

**Ishtiaque Hossain**
- GitHub: [@Ishtiaque-h](https://github.com/Ishtiaque-h)
- LinkedIn: [@ishtiaque-h](https://linkedin.com/in/ishtiaque-h)

---

## ğŸ™ Acknowledgments

- Dataset: [Kaggle - Students Performance in Exams](https://www.kaggle.com/datasets/spscientist/students-performance-in-exams)
- Inspiration: Production ML systems at companies like Netflix, Uber, Airbnb
- Tools: FastAPI, scikit-learn, XGBoost, CatBoost, MLflow, GitHub Actions, Google Cloud

---

**Related Projects**:
- [Boston House Price Prediction](https://github.com/Ishtiaque-h/boston-house-pricing.git)

---

**â­ If you find this project helpful, please consider giving it a star!**