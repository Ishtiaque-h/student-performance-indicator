name: Retrain and Rollout

on:
  workflow_dispatch:
  schedule:
    - cron: "0 7 * * 1"  # every Monday 07:00 UTC

permissions:
  contents: read
  id-token: write

env:
  PROJECT_ID: ${{ vars.GCP_PROJECT_ID }} # e.g., student-performance-indicator
  REGION: ${{ vars.GCP_REGION }} # e.g., us-central1
  MODEL_REGISTRY_URI: ${{ vars.MODEL_REGISTRY_URI }} # gs://bucket/student-performance
  ARTIFACTS_DIR: /tmp/artifacts
  MLFLOW_EXPERIMENT_NAME: student-performance
  MLFLOW_DIR: /tmp/mlruns
  MLFLOW_TRACKING_URI: file:///tmp/mlruns
  PROMOTE_IF_TEST_R2_AT_LEAST: "0.10"
  MLFLOW_GCS_URI: ${{ vars.MLFLOW_GCS_URI }} # e.g. gs://bucket/mlflow/student-performance

# after training finishes, sync mlruns to GCS in a job step


jobs:
  retrain:
    environment: production
    runs-on: ubuntu-latest
    env:
        SERVICE: ${{ vars.CLOUD_RUN_SERVICE }} # e.g., student-performance-api (production)

    steps:
      - uses: actions/checkout@v4

      - id: auth
        uses: google-github-actions/auth@v3
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}

      - uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.PROJECT_ID }}

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[api,dev,ml,mlops]"  # includes api, dev, ml, mlops deps; remove extras you don't need for faster runs

      - name: Prepare run dirs
        run: |
          mkdir -p "$MLFLOW_DIR" "$ARTIFACTS_DIR"

      - name: Train + publish artifacts
        id: publish
        run: |
          python scripts/train_and_publish.py --registry-uri "${MODEL_REGISTRY_URI}" --also-latest | tee publish.out
          RUN_ID=$(grep '^RUN_ID=' publish.out | cut -d= -f2)
          echo "RUN_ID=$RUN_ID" >> $GITHUB_ENV

      - name: Sync mlruns to GCS
        run: |
          gcloud storage rsync -r "${{ env.MLFLOW_DIR }}" "${{ env.MLFLOW_GCS_URI }}"

      - name: Gate and promote model
        shell: bash
        run: |
          set -euo pipefail

          # 1) Read metric from model_report.json
          TEST_R2="$(python -c "import json;print(json.load(open('artifacts/model_report.json'))['best_model']['test_r2'])")"
          export TEST_R2
          echo "TEST_R2=$TEST_R2" >> "$GITHUB_ENV"
          echo "TEST_R2=${TEST_R2}"

          # 2) Gate promotion (Tier 1: fixed threshold)
          python - <<'PY'
          import os
          thr = float(os.getenv("PROMOTE_IF_TEST_R2_AT_LEAST", "0.10"))
          val = float(os.environ["TEST_R2"])
          print(f"threshold={thr}, test_r2={val}")
          if val < thr:
              raise SystemExit("Not promoting: metric below threshold.")
          PY

          # 3) Upload to GCS (new version)
          MODEL_VERSION="run-$(date +%Y%m%d-%H%M%S)-${GITHUB_SHA::7}"
          GCS_DEST="${MODEL_REGISTRY_URI}/${MODEL_VERSION}"
          gcloud storage rsync -r "artifacts" "${GCS_DEST}"
          
          # 4) Point Cloud Run to the new model (do NOT overwrite other env vars)
          echo "Updating Cloud Run service: ${SERVICE} in ${PROJECT_ID}/${REGION}"
          gcloud run services update "${SERVICE}" \
            --region "${REGION}" \
            --project "${PROJECT_ID}" \
            --update-env-vars "MODEL_REGISTRY_URI=${GCS_DEST},ARTIFACTS_DIR=${ARTIFACTS_DIR},FORCE_MODEL_DOWNLOAD=1"

