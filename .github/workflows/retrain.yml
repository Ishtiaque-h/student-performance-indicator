name: Retrain and Rollout

on:
  workflow_dispatch:
  schedule:
    - cron: "0 7 * * 1"  # every Monday 07:00 UTC

permissions:
  contents: read
  id-token: write

env:
  PROJECT_ID: ${{ vars.GCP_PROJECT_ID }} # e.g., student-performance-indicator
  REGION: ${{ vars.GCP_REGION }} # e.g., us-central1
  MODEL_REGISTRY_URI: ${{ vars.MODEL_REGISTRY_URI }} # gs://bucket/student-performance
  ARTIFACTS_DIR: /tmp/artifacts
  MLFLOW_EXPERIMENT_NAME: student-performance
  MLFLOW_DIR: /tmp/mlruns
  MLFLOW_TRACKING_URI: file:///tmp/mlruns
  PROMOTE_IF_TEST_R2_AT_LEAST: "0.10"
  MLFLOW_GCS_URI: ${{ vars.MLFLOW_GCS_URI }} # e.g. gs://bucket/mlflow/student-performance

# after training finishes, sync mlruns to GCS in a job step


jobs:
  retrain:
    environment: staging
    runs-on: ubuntu-latest
    env:
        SERVICE: ${{ vars.CLOUD_RUN_SERVICE }} # e.g., student-performance-api-staging (staging)

    steps:
      - uses: actions/checkout@v4

      - id: auth
        uses: google-github-actions/auth@v3
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}

      - uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.PROJECT_ID }}

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[all]"  # includes api, dev, ml, mlops deps; remove extras you don't need for faster runs

      - name: Prepare run dirs
        run: |
          mkdir -p "$MLFLOW_DIR" "$ARTIFACTS_DIR"

      - name: Train + publish artifacts (run index only)
        id: publish
        shell: bash
        run: |
          set -euo pipefail

          python scripts/train_and_publish.py \
            --registry-uri "${MODEL_REGISTRY_URI}" \
            --index-latest | tee publish.out

          RUN_ID="$(grep '^RUN_ID=' publish.out | cut -d= -f2)"
          RUN_URI="$(grep '^RUN_URI=' publish.out | cut -d= -f2)"

          echo "RUN_ID=$RUN_ID" >> "$GITHUB_ENV"
          echo "RUN_URI=$RUN_URI" >> "$GITHUB_ENV"

          echo "RUN_ID=$RUN_ID"
          echo "RUN_URI=$RUN_URI"

      - name: Sync mlruns to GCS
        run: |
          gcloud storage rsync -r "${MLFLOW_DIR}" "${MLFLOW_GCS_URI}/${RUN_ID}"

      - name: Gate and promote model
        shell: bash
        run: |
          set -euo pipefail

          # Read metric and gate â€” all in one Python block to avoid shell quoting issues
          python - <<PY
          import json, os, sys

          report_path = os.path.join(os.environ["GITHUB_WORKSPACE"], "artifacts", "model_report.json")
          report = json.load(open(report_path))
          test_r2 = report["best_model"]["test_r2"]
          threshold = float(os.environ.get("PROMOTE_IF_TEST_R2_AT_LEAST", "0.10"))

          print(f"test_r2={test_r2}, threshold={threshold}")

          with open(os.environ["GITHUB_ENV"], "a") as f:
              f.write(f"TEST_R2={test_r2}\n")

          if test_r2 < threshold:
              sys.exit(f"Not promoting: test_r2={test_r2} < threshold={threshold}")
          PY

          # Write the promoted model URI to GCS
          echo "${RUN_URI}" | gcloud storage cp - "${MODEL_REGISTRY_URI}/promoted/latest_uri.txt"
          echo "Promoted model URI written: ${RUN_URI}"
          
      - name: Rollout to STAGING (recommended)
        shell: bash
        run: |
          set -euo pipefail
          echo "Deploying candidate model to staging: $RUN_URI"
          echo "Updating Cloud Run service: ${SERVICE} in ${PROJECT_ID}/${REGION}"
          gcloud run services update "${SERVICE}" \
            --region "${REGION}" \
            --project "${PROJECT_ID}" \
            --update-env-vars "GCS_ARTIFACTS_URI=${RUN_URI},ARTIFACTS_DIR=${ARTIFACTS_DIR},FORCE_MODEL_DOWNLOAD=1"



