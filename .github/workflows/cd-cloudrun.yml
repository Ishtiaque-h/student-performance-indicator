name: CD - Deploy to Cloud Run (tag)

on:
  push:
    tags:
      - "v*"
  workflow_dispatch:

permissions:
  contents: read
  id-token: write

jobs:
  smoke:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Install (for tests)
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[api,dev]"   # add api so smoke tests can import API code safely

      - name: Run smoke tests
        run: pytest -m smoke -q

  deploy:
    environment: production
    needs: [smoke]
    runs-on: ubuntu-latest
    env:
      PROJECT_ID: ${{ vars.GCP_PROJECT_ID }} # e.g., student-performance-indicator
      REGION: ${{ vars.GCP_REGION }} # e.g., us-central1
      SERVICE: ${{ vars.CLOUD_RUN_SERVICE }} # e.g., student-performance-api (production)
      ARTIFACT_REPO: ${{ vars.ARTIFACT_REPO }} # e.g., student-performance
      MODEL_REGISTRY_URI: ${{ vars.MODEL_REGISTRY_URI }} # gs://bucket/student-performance


    steps:
      - uses: actions/checkout@v4

      - name: Auth to GCP (WIF)
        uses: google-github-actions/auth@v3
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}

      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.PROJECT_ID }}

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Install (deploy deps)
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[api]"  # includes api, dev, ml, mlops deps; remove extras you don't need for faster installs

      - name: Read promoted model URI from registry
        shell: bash
        run: |
          set -euo pipefail
          : "${MODEL_REGISTRY_URI:?MODEL_REGISTRY_URI must be set}"

          # Read the URI of the model that passed staging quality gate
          PROMOTED_URI="$(gcloud storage cat "${MODEL_REGISTRY_URI}/promoted/latest_uri.txt")"
          
          if [ -z "${PROMOTED_URI}" ]; then
            echo "ERROR: No promoted model URI found. Run retrain workflow first."
            exit 1
          fi

          echo "Promoting model: ${PROMOTED_URI}"
          echo "ARTIFACTS_URI=${PROMOTED_URI}" >> "$GITHUB_ENV"

      - name: Configure Docker for Artifact Registry
        run: gcloud auth configure-docker ${{ env.REGION }}-docker.pkg.dev --quiet

      - name: Build and Push image
        shell: bash
        run: |
          set -euo pipefail
          TAG="${GITHUB_REF_NAME}"  # e.g. v0.2.0
          IMAGE_URI="${REGION}-docker.pkg.dev/${PROJECT_ID}/${ARTIFACT_REPO}/${SERVICE}:${TAG}"
          echo "IMAGE_URI=${IMAGE_URI}" >> "$GITHUB_ENV"
          echo "TAG=${TAG}" >> "$GITHUB_ENV"   # ← add this line
          docker build --no-cache -t "${IMAGE_URI}" .
          docker push "${IMAGE_URI}"

      - name: Show deploy target
        run: |
          ENVIRONMENT="${{ job.environment.name }}"  # staging or production
          echo "ENVIRONMENT=$ENVIRONMENT" >> "$GITHUB_ENV"
          echo "PROJECT_ID=${{ env.PROJECT_ID }}"
          echo "REGION=${{ env.REGION }}"
          echo "SERVICE=${{ env.SERVICE }}"

      - name: Deploy to Cloud Run
        shell: bash
        run: |
          set -euo pipefail

          : "${MODEL_REGISTRY_URI:?MODEL_REGISTRY_URI must be set}"
          : "${ARTIFACTS_URI:?ARTIFACTS_URI must be set — was promoted model URI read correctly?}"

          echo "Deploying with ARTIFACTS_URI=${ARTIFACTS_URI}"

          # Fail fast: do not deploy if promoted artifacts aren't present
          gcloud storage ls "${ARTIFACTS_URI}/model.pkl" >/dev/null
          gcloud storage ls "${ARTIFACTS_URI}/preprocessor.pkl" >/dev/null

          # Build env vars string — use ARTIFACTS_URI from the promoted pointer
          ENV_VARS="ARTIFACTS_DIR=/tmp/artifacts,GCS_ARTIFACTS_URI=${ARTIFACTS_URI},FORCE_MODEL_DOWNLOAD=1"
          
          echo "Setting environment variables: ${ENV_VARS}"

          # Get the image digest to force new revision
          IMAGE_DIGEST=$(gcloud artifacts docker images describe "${IMAGE_URI}" \
            --format='value(image_summary.digest)')
          IMAGE_WITH_DIGEST="${REGION}-docker.pkg.dev/${PROJECT_ID}/${ARTIFACT_REPO}/${SERVICE}@${IMAGE_DIGEST}"

          echo "Deploying image with digest: ${IMAGE_WITH_DIGEST}"

          # Create unique revision suffix from tag
          REVISION_SUFFIX=$(echo "${TAG}" | sed 's/[^a-z0-9-]/-/g' | sed 's/^-*//' | sed 's/-*$//' | cut -c1-20)
          
          echo "Using revision suffix: ${REVISION_SUFFIX}"

          gcloud run deploy "${SERVICE}" \
            --project "${PROJECT_ID}" \
            --region "${REGION}" \
            --image "${IMAGE_WITH_DIGEST}" \
            --port 8080 \
            --allow-unauthenticated \
            --service-account "${{ secrets.GCP_API_SERVICE_ACCOUNT }}" \
            --revision-suffix "${REVISION_SUFFIX}" \
            --set-env-vars "${ENV_VARS}"
            
          echo "Deployment complete"
            
      - name: Post-deploy smoke
        shell: bash
        run: |
          set -euo pipefail

          SERVICE_URL="$(gcloud run services describe "${SERVICE}" \
            --project "${PROJECT_ID}" \
            --region "${REGION}" \
            --format='value(status.url)')"

          echo "Service URL: ${SERVICE_URL}"

          # ---- Health must be 200 ----
          curl -fsS "${SERVICE_URL}/health" | tee /tmp/health.json

          # ---- Happy-path predict must be 200 and contain prediction ----
          HTTP_CODE="$(curl -sS -o /tmp/predict.json -w "%{http_code}" \
            -X POST "${SERVICE_URL}/predict" \
            -H "Content-Type: application/json" \
            -d '{
              "gender":"female",
              "race_ethnicity":"group B",
              "parental_level_of_education":"bachelor'\''s degree",
              "lunch":"standard",
              "test_preparation_course":"none"
            }')"

          echo "predict status: ${HTTP_CODE}"
          cat /tmp/predict.json

          if [ "${HTTP_CODE}" -ne 200 ]; then
            echo "ERROR: /predict did not return 200"
            exit 1
          fi

          python - <<'PY'
          import json
          obj = json.load(open("/tmp/predict.json"))
          assert "prediction" in obj, obj
          PY

          # ---- Negative schema check should return 422 (or 400 depending on your design) ----
          BAD_CODE="$(curl -sS -o /tmp/bad.json -w "%{http_code}" \
            -X POST "${SERVICE_URL}/predict" \
            -H "Content-Type: application/json" \
            -d '{
              "gender":"female",
              "race_ethnicity":"group B",
              "parental_level_of_education":"bachelor'\''s degree",
              "test_preparation_course":"none"
            }')"

          echo "bad predict status: ${BAD_CODE}"
          cat /tmp/bad.json

          if [ "${BAD_CODE}" -ne 422 ] && [ "${BAD_CODE}" -ne 400 ]; then
            echo "ERROR: expected 422/400 for schema failure"
            exit 1
          fi